{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flyaflya/persuasive/blob/main/demoNotebooks/xarrayIntro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install daft matplotlib --upgrade"
      ],
      "metadata": {
        "id": "X1rOkoU6NAQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCEzzpvpM4os"
      },
      "source": [
        "# Multi-Dimensional Arrays for Decision Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "results": "hide",
        "cellView": "form",
        "id": "AR1rIaFVM4ov"
      },
      "source": [
        "#@title A Full Decision Model\n",
        "#| echo: false\n",
        "#| include: false\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from functools import partial, partialmethod\n",
        "import daft   ### %pip install -U git+https://github.com/daft-dev/daft.git\n",
        "from numpy.random import default_rng\n",
        "import numpy as np\n",
        "\n",
        "class dag(daft.PGM):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        daft.PGM.__init__(self, *args, **kwargs)\n",
        "    \n",
        "    obsNode = partialmethod(daft.PGM.add_node, aspect = 2.2, fontsize = 10, plot_params = {'facecolor': 'cadetblue'})\n",
        "    decNode = partialmethod(daft.PGM.add_node, aspect = 2.2, fontsize = 10, shape = \"rectangle\", plot_params = {'facecolor': 'thistle'})\n",
        "    detNode = partialmethod(daft.PGM.add_node, aspect = 5.4, fontsize = 9.25, alternate = True, plot_params = {'facecolor': 'aliceblue'})\n",
        "    latNode = partialmethod(daft.PGM.add_node, scale = 1.2, aspect = 2.2, fontsize = 10, plot_params = {'facecolor': 'aliceblue'})\n",
        "    detNodeBig = partialmethod(daft.PGM.add_node, scale = 1.6, aspect = 2.25, fontsize = 10, alternate = True, plot_params = {'facecolor': 'aliceblue'})\n",
        "    latNodeBig = partialmethod(daft.PGM.add_node, scale = 1.6, aspect = 2.2, fontsize = 10, plot_params = {'facecolor': 'aliceblue'})\n",
        "    \n",
        "pgm = dag(dpi = 300, alternate_style=\"outer\")\n",
        "pgm.latNode(\"d\",\"Demand\\n\"+r\"$(d_i)$\",1,2)\n",
        "pgm.decNode(\"q\",\"Order\\n\" + r\"Qty$(q)$\",6,2)\n",
        "pgm.detNode(\"pi\",\"Profit: \" + r\"$\\pi(d_i,q) =$\" + \"\\n\" + r\"$3 \\times \\min(d_i,q) - 1 \\times q$\", 3.5,2)\n",
        "pgm.detNode(\"l\",\"Lost Sales\\n\" + r\"$\\ell(d_i,q) = \\max(0,d_i-q)$\", 3.5,1)\n",
        "pgm.add_edge(\"d\",\"pi\")\n",
        "pgm.add_edge(\"q\",\"pi\")\n",
        "pgm.add_edge(\"d\",\"l\")\n",
        "pgm.add_edge(\"q\",\"l\")\n",
        "pgm.add_plate([0.25, 0.25, 5, 2.25], label = \"Sim Num:\\n\" + r\"$i = 1, 2, 3$\", \n",
        "              label_offset = (2,2), rect_params = dict({\"fill\": False, \"linestyle\": \"dashed\", \"edgecolor\": \"cadetblue\"}))\n",
        "pgm.add_plate([2, -0.1, 4.7, 2.75], label = \"Order Quantity:\\n\" + r\"$q = 30, 40, 50$\", \n",
        "              label_offset = (2,2), position = \"bottom right\", rect_params = dict({\"fill\": False, \"linestyle\": \"dotted\", \"edgecolor\": \"darkorchid\"}))\n",
        "pgm.show(dpi = 140)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idsZ4GOFM4ox"
      },
      "source": [
        "Around the nodes, notice the new addition of rectangles,technically called _plates_.  \n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "i &\\equiv \\textrm{Index for simulation draws. } i \\in \\{1, 2, 3\\}\\\\\n",
        "d_i &\\equiv \\textrm{Daily demand for newspapers, and}\\\\\n",
        "d_i &\\sim \\textrm{Binomial}(n=200,p=0.2).\\\\\n",
        "q &\\equiv \\textrm{Order quantity chosen by decision-maker, where}\\\\\n",
        "q &\\in \\{30, 40, 50\\} \\qquad \\textit{   (potentially good order qtys.)}.\\\\\n",
        "\\pi &\\equiv \\textrm{Daily profit is revenue minus expenses.}\\\\\n",
        "\\pi(d_i,q) &= 3 \\times \\min(d_i,q) - 1 \\times q \\qquad \\textit{   (cannot sell more than ordered)}.\\\\\n",
        "\\ell &\\equiv \\textrm{Lost sales.  Unmet demand due to being out of stock.}\\\\\n",
        "\\ell(d_i,q) &= \\max(0, d-q) \\qquad \\textit{   (lost sales cannot be negative)}.\n",
        "\\end{aligned}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPjDkVVhM4oy"
      },
      "source": [
        "potentialCusts = 200\n",
        "purchaseProb = 0.2\n",
        "\n",
        "rng = default_rng(seed = 111) \n",
        "numSims = 3\n",
        "\n",
        "# create data frame to store simulated demand\n",
        "newsDF = pd.DataFrame({\"simNum\": range(1, numSims+1),  # sequence of 1 to 100\n",
        "                   \"demand\": rng.binomial(n = potentialCusts, \n",
        "                                          p = purchaseProb,\n",
        "                                          size = numSims)})\n",
        "\n",
        "## google SEARCH PHRASE: get element-wise minimum of two columns in pandas dataframe\n",
        "newsDF[\"profit_q40\"] = 3 * np.minimum(newsDF.demand,40) - 1 * 40\n",
        "newsDF[\"lostSales_q40\"] = np.maximum(0,newsDF.demand - 40)\n",
        "\n",
        "# view first few 5 rows of newsDF\n",
        "newsDF.iloc[:5,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTktsxDbM4oy"
      },
      "source": [
        "It will feel cumbersome to add more columns for each order quantity's profit and each quantity's lost sales into a dataframe.  There must be a better way to structure how we store this data.  \n",
        "\n",
        "## The `xarray` Package\n",
        "\n",
        "### `DataArray`:  In its simplest 1-dimensional form, a `DataArray` is just a collection of values, like the column of dataframe (`pandas.Series`) or a one-dimensional array of values (`numpy.ndarray`).  We can create a simple `DataArray` using its constructor function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zXM9o4iM4oz"
      },
      "source": [
        "from numpy.random import default_rng\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "\n",
        "rng = default_rng(seed = 111)  ## set random seed \n",
        "demand = rng.binomial(n=200,p=0.2,size=3)   ## get demand values\n",
        "\n",
        "## make data array\n",
        "xr.DataArray(data = demand)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmmBLUOvM4oz"
      },
      "source": [
        "\n",
        "*   dimension key-value pair `dim_0: 3` tells us that the cardinality of our \n",
        "demand array is 3\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KEQLtJeM4oz"
      },
      "source": [
        "## make data array with labelled dimension name\n",
        "xr.DataArray(data = demand, dims = \"draw\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn23rMM8M4o0"
      },
      "source": [
        "## explicit labeling of coordinates - must use name now to create dataset later\n",
        "demandDA = xr.DataArray(data = demand, coords = {\"draw\": np.arange(3)+1}, name = \"demand\")\n",
        "demandDA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hbv7S3rpM4o0"
      },
      "source": [
        "Notice, we can drop the `dims` arguments as the dimension name is supplied in the dictionary object passed to the `coords` argument."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Repeating the graphical model\n",
        "pgm.show(dpi=120)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Nsd7VnhYP5Pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9iRMJNHM4o1"
      },
      "source": [
        "## creating a DataArray of order quantities - must use name now to create dataset later\n",
        "orderDA = xr.DataArray(data = [30, 40, 50], \n",
        "                       coords = {\"orderQtyIndex\": [30,40,50]},\n",
        "                       name = \"orderQty\")\n",
        "orderDA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merge the two data arrays into a dataset."
      ],
      "metadata": {
        "id": "mO6jEIVXQMuf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUPPqJXcM4o2"
      },
      "source": [
        "# create dataset by combining data arrays\n",
        "newsvDS = xr.merge([demandDA,orderDA])\n",
        "newsvDS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ4IkEz4M4o2"
      },
      "source": [
        "Our `Dataset` container now has the dimensions implied by the plate indices in @fig-newsvGM2, namely `draw: 3  orderQty: 3`.  In math terms we have two sets, one is a set of demand draws where cardinality $|D|=3$; the other a set of order quantities with cardinality $|Q|=3$.  Thus, the set of all ordered pairs $(d_i,q)$ to be used for calculation of profit and lost sales will have cardinality $|D| \\times |Q| = 9$.  Thus, our simulation of potential  $\\pi(d_i,q)$ and $\\ell(d_i,q)$ values will each have 9 elements.\n",
        "\n",
        "## Seven mental models of dataset manipulation\n",
        "\n",
        "The seven most important ways we might want to manipulate a data array or dataset is to:\n",
        "\n",
        "1. Assign: `.assign()` or `assign_coords()`: Add data variables with broadcasting and array math.  (Can also use dict-like methods)\n",
        "2. Subset: `.sel()` or `.where()` subset a data array or dataset based on coordinates or data values, respectively.\n",
        "3. Drop: `.drop_vars()` or `.drop_dims()`: Remove an explicit list of data variables or remove all data variables indexed by a particular dimension. \n",
        "4. Sort: `.sortby()` sorts or arranges a data array or dataset based on data values or coordinate values.\n",
        "5. Aggregate: See the [xarray documentation](https://docs.xarray.dev/en/stable/api.html?highlight=aggregation#) for a list of aggregation functions.  These functions will collapse all the data of a given dimension; for example one can collapse a time dimension using the `mean()` aggregation method to get the average value for all of time.\n",
        "6. Split-Apply-Combine: `.groupby()` and `DatasetGroupBy.foo()` are usually used in combination to 1) _split_ the dataset into groups based on levels of a variable, 2) _apply_ a function (e.g. `foo()`) to each group's dataset individually, and then 3) _combine_ the modified datasets. See the [xarray documentation](https://docs.xarray.dev/en/stable/api.html?highlight=Groupby#groupby-objects) for more details. \n",
        "7. Merge(join): Getting information from two datasets to intelligently combine.\n",
        "\n",
        "### 1 - Assign: Adding Data Arrays\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JCe1hUUM4o2"
      },
      "source": [
        "(  ## open parenthesis to start readable code\n",
        "    newsvDS\n",
        "    .assign(soldNewspapers = np.minimum(newsvDS.demand,newsvDS.orderQty))\n",
        ") ## close parenthesis finishes the \"method chaining\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlve-DMbM4o3"
      },
      "source": [
        "#| eval: false\n",
        "(  ## open parenthesis to start readable code\n",
        "    newsvDS\n",
        "    .assign(soldNewspapers = np.minimum(newsvDS.demand,newsvDS.orderQty))\n",
        "    .assign(revenue = 3 * newsvDS.soldNewspapers)\n",
        ") ## close parenthesis finishes the \"method chaining\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F48oW-VyM4o3"
      },
      "source": [
        "The above code will yield an error:\n",
        "\n",
        "```\n",
        "AttributeError: 'Dataset' object has no attribute 'soldNewspapers'\n",
        "```\n",
        "\n",
        "The last assignment apparently does not have visibility into the newly created data for `soldNewspapers`.  To pass the _current state_ of the dataset to the `.assign()` method, we use a `lambda` function.  The `lambda` function has syntax `lambda arguments : expression` where `lambda` is a keyword telling python to expect an argument (or arguments), followed by a colon (`:`), and then an expression for what will be returned by the function..  Here is updated code that works:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHj3_ps7M4o3"
      },
      "source": [
        "(  ## open parenthesis to start readable code\n",
        "    newsvDS\n",
        "    .assign(soldNewspapers = np.minimum(newsvDS.demand,newsvDS.orderQty))\n",
        "    .assign(revenue = lambda DS: 3 * DS.soldNewspapers)\n",
        ") ## use lambda function to get current state of dataset in chain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZLOuenEM4o3"
      },
      "source": [
        "## YOUR TURN:  Use `assign` to add a lost sales data variable to the dataset.  Modify the below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqCRsj7OM4o4"
      },
      "source": [
        "newsvDS = (newsvDS\n",
        "            .assign(soldNewspapers = np.minimum(newsvDS.demand,newsvDS.orderQty))\n",
        "            .assign(revenue = lambda DS: 3 * DS.soldNewspapers)\n",
        "            .assign(expense = 1 * newsvDS.orderQty)\n",
        "            .assign(profit = lambda DS: DS.revenue - DS.expense)\n",
        ")\n",
        "\n",
        "(newsvDS\n",
        " .to_dataframe())  #dataframe for printing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVMJq5fdM4o4"
      },
      "source": [
        "Note, one can also add columns directly using dict-like indexing when chains of operations are not required.  The following code would work similarly to what we did earlier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUD4jUUnM4o4"
      },
      "source": [
        "newsvDS[\"lostSales\"] = np.maximum(0, newsvDS.demand - newsvDS.orderQty)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-Lg50UFM4o4"
      },
      "source": [
        "### 2 - Select a subset of the data array or dataset\n",
        "\n",
        "Syntax of help documentation is often `packagename.Class.method`.  Let's find the `sel` method in the xarray documentation. (https://docs.xarray.dev/en/stable/user-guide/indexing.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc874LIrM4o4"
      },
      "source": [
        "# select a particular value for a dimension\n",
        "newsvDS.sel(orderQtyIndex = 30) # returns 1-d dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zew0qgxxM4o5"
      },
      "source": [
        "`xarray` follows the pandas convention for selecting a range of coordinate values to keep using the `slice` function.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmNoP3kxM4o5"
      },
      "source": [
        "# slicing returns all values inside the range (inclusive) \n",
        "# as long as the index labels are monotonic increasing\n",
        "newsvDS.sel(orderQtyIndex = slice(36,58))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rKlevrjM4o5"
      },
      "source": [
        "Slicing returns a smaller dataset or data array based on coordinates, but often we want a smaller dataset based on data values.  In these cases, we apply the `.where()` method where the argument is some logical condition for which data to keep:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeU29la4M4o5"
      },
      "source": [
        "# need to explicitly use DataSet.DataArray syntax for \n",
        "# filtering out rows that do not meet condition\n",
        "newsvDS.assign(lostSales = lambda DS: DS.revenue - DS.expense).where(newsvDS.lostSales > 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4S1S4tAM4o5"
      },
      "source": [
        "Often times, the `lambda` syntax for anonymous functions gets used to pass in the dataset name:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yr71C5wM4o5"
      },
      "source": [
        "(\n",
        "    newsvDS.where(lambda x: x.lostSales > 0, drop = True)\n",
        "    .to_dataframe()  #convert to pandas dataframe for printing\n",
        "    .dropna() # pandas method to remove NaN rows\n",
        " ) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EXA0H3kM4o6"
      },
      "source": [
        "## YOUR TURN:  \n",
        "Experiment with omitting the `pandas.DataFrame.dropna` method from the above.  What's different.   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## experiment here:\n"
      ],
      "metadata": {
        "id": "OG3IFMkiTSx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 3 - Drop Dimensions\n",
        "\n",
        "The `drop_dims()` method returns a new object by dropping a full dimension from a dataset along with any variables whose coordinates rely on that dimension."
      ],
      "metadata": {
        "id": "sM5UvVIqTVeh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEQo8oFKM4o6"
      },
      "source": [
        "newsvDS.drop_dims(\"orderQtyIndex\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr-Le6IgM4o6"
      },
      "source": [
        "Above, the order quantity dimension is dropped along with all the data variables whose value depended on order quantity: `orderQty`, `soldNewspapers`, `revenue`, `expense`, `profit`, and `lostSales`.\n",
        "\n",
        "If you want to just drop some of the data variables, you use `drop_vars()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xql27qCM4o6"
      },
      "source": [
        "newsvDS.drop_vars([\"revenue\",\"expense\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHGo92eVM4o6"
      },
      "source": [
        "### 4 - Sort a data array or dataset based on data values or data values.\n",
        "\n",
        "We will typically want dataframe-like reports generated out of `xarray` as a last step in data manipulation.  We will rely on `pandas.DataFrame.sort_values()` to help us for this mental model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weUjUhrkM4o7"
      },
      "source": [
        "(newsvDS\n",
        " .to_dataframe()\n",
        " .sort_values(\"profit\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YOUR TURN:\n",
        "Using `.sort_values(\"profit\", ascending = True)` reverse the sort order so maximum profit is first."
      ],
      "metadata": {
        "id": "O2ifVlPpTnqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment Here:\n"
      ],
      "metadata": {
        "id": "ocwywxJvT3uK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouUD_Wn4M4o7"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "### 5 - Aggregation \n",
        "\n",
        "See the `xarray` documentation at https://docs.xarray.dev/en/stable/api.html#id6 for a complete list of aggregation functions.\n",
        "\n",
        "1) Aggregate the information in a data array. \n",
        "2) Assign the output of the aggregation to a new data array in a pre-existing dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbb5dlv2M4o7"
      },
      "source": [
        "## collapse the 100 draws into 1 summary statistic\n",
        "(\n",
        "    newsvDS\n",
        "    .profit\n",
        "    .mean(dim = \"draw\")\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAghVf-_M4o7"
      },
      "source": [
        "Notice, this returns a `DataArray` object.  We will then keep our data and summary statistics together in one dataset by adding the array back to the original dataset using `assign()`.  Here the two-step workflow is demonstrated to return expected profit and expected lost sales for each order quantity:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Hr8Bw1iM4o7"
      },
      "source": [
        "## create mean summary stats\n",
        "(\n",
        "    newsvDS\n",
        "    .assign(expProfit = newsvDS.profit.mean(dim=\"draw\"))\n",
        "    .assign(expLossSales = newsvDS.lostSales.mean(dim=\"draw\"))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKHZn1_1M4o8"
      },
      "source": [
        "Feel free to play around with these other frequently-used aggregation functions include `count`, `first`, `last`, `max`, `mean`, `median`, `min`, `quantile`, and `sum.`\n",
        "\n",
        "### 6 - Split-Apply-Combine\n",
        "\n",
        "See the [xarray documentation](https://docs.xarray.dev/en/stable/api.html?highlight=Groupby#groupby-objects) for more details using split-apply-combine:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## find average profit by orderQty\n",
        "## see docuemntation here: https://docs.xarray.dev/en/stable/generated/xarray.core.groupby.DatasetGroupBy.mean.html\n",
        "(\n",
        "    newsvDS\n",
        "    .get(\"profit\")\n",
        "    .groupby(\"orderQtyIndex\")\n",
        "    .mean(...)\n",
        ").to_dataframe()"
      ],
      "metadata": {
        "id": "UpFQv0uwV_y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YOUR TURN\n",
        "Find the maximum lost sales by order quantity."
      ],
      "metadata": {
        "id": "94KfqeldWZ1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code Here:"
      ],
      "metadata": {
        "id": "mCYIjZ2mWe3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7 - Merge(join):\n",
        "\n",
        "To be shown after the dinner break."
      ],
      "metadata": {
        "id": "RdFKsMIKV83X"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}